"""
Model Court Web API Backend

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ Flask APIï¼Œæä¾› Model Court çš„ Web æ¥å£ã€‚
ç”¨äºäº‹å®æ ¸æŸ¥ï¼šåˆ¤æ–­è¾“å…¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸ç¬¦åˆäº‹å®çš„å†…å®¹ã€‚
"""

import asyncio
import os
import sys
from datetime import timedelta
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS

# å¯é€‰: ä½¿ç”¨ python-dotenv è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    # åŠ è½½ example ç›®å½•ä¸‹çš„ .env æ–‡ä»¶
    env_path = Path(__file__).parent.parent / ".env"
    load_dotenv(dotenv_path=env_path)
    print(f"âœ… Loaded .env from: {env_path}")
except ImportError:
    print("âš ï¸  æç¤º: å®‰è£… python-dotenv å¯è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶: pip install python-dotenv")

# æ·»åŠ çˆ¶ç›®å½•åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from model_court import Court, Prosecutor, Jury, Judge, SqliteCourtCode
from model_court.references import LocalRAGReference, SimpleTextStorage

app = Flask(__name__, static_folder='../frontend', static_url_path='')
CORS(app)

# å…¨å±€å˜é‡å­˜å‚¨ Court å®ä¾‹
court_instance = None
initialization_error = None

def initialize_court():
    """åˆå§‹åŒ– Court å®ä¾‹"""
    global court_instance, initialization_error
    
    try:
        # è®¾ç½®è·¯å¾„
        base_path = Path(__file__).parent
        db_path = base_path / "court_history.db"
        rag_path = base_path.parent / "data" / "rag_storage"
        rag_docs = base_path.parent / "data" / "rag_documents"
        
        # 1. åˆå§‹åŒ– Court Code
        print("Initializing Court Code...")
        court_code = SqliteCourtCode(
            db_path=str(db_path),
            embedding_model="MiniLM",
            default_validity_period=timedelta(days=30),
            enable_vector_search=True
        )
        
        # 2. åˆå§‹åŒ– Prosecutorï¼ˆå¯ç”¨è‡ªåŠ¨æ‹†åˆ†ï¼‰
        print("Initializing Prosecutor...")
        prosecutor = Prosecutor(
            court_code=court_code,
            auto_claim_splitting=True,  # å¯ç”¨è‡ªåŠ¨æ‹†åˆ†
            model={
                "provider": "openai_compatible",
                "base_url": "https://openrouter.ai/api/v1",
                "api_key": os.getenv("OPENROUTER_API_KEY", ""),
                "model_name": "openai/gpt-3.5-turbo",
                "temperature": 0.1
            },
            prosecutor_prompt="ä½ æ˜¯ä¸€åä¸¥æ ¼çš„æ£€å¯Ÿå®˜ã€‚è¯·å°†è¾“å…¥çš„æ¡ˆæƒ…ï¼ˆCaseï¼‰æ‹†è§£ä¸ºç‹¬ç«‹çš„ã€å¯éªŒè¯çš„äº‹å®æ–­è¨€ï¼ˆClaimsï¼‰ã€‚"
        )
        
        # 3. åˆå§‹åŒ– Reference æº
        print("Initializing References...")
        
        # RAG çŸ¥è¯†åº“
        try:
            rag_reference = LocalRAGReference(
                collection_name="fact_check_knowledge",
                persist_directory=str(rag_path),
                embedding_model="MiniLM",
                source_folder=str(rag_docs) if rag_docs.exists() else None,
                mode="append",
                top_k=3
            )
        except Exception as e:
            print(f"Warning: RAG initialization failed: {e}")
            rag_reference = None
        
        # ç®€å•æ–‡æœ¬å­˜å‚¨ï¼ˆåŸºç¡€äº‹å®ï¼‰
        # ä»æ–‡ä»¶è¯»å–åŸºç¡€äº‹å®çŸ¥è¯†
        basic_facts_file = base_path.parent / "data" / "rag_documents" / "basic_facts.txt"
        if basic_facts_file.exists():
            with open(basic_facts_file, "r", encoding="utf-8") as f:
                basic_facts_text = f.read()
            text_reference = SimpleTextStorage(text=basic_facts_text)
            print(f"âœ… Loaded basic facts from: {basic_facts_file}")
        else:
            print(f"âš ï¸  Warning: basic_facts.txt not found at {basic_facts_file}")
            text_reference = SimpleTextStorage(text="åŸºç¡€äº‹å®çŸ¥è¯†æ–‡ä»¶æœªæ‰¾åˆ°ã€‚")

        
        # 4. åˆå§‹åŒ– Juries
        print("Initializing Juries...")
        juries = []
        
        # è·å– OpenRouter API Keyï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
        openrouter_key = os.getenv("OPENROUTER_API_KEY", "")
        
        # ä½¿ç”¨ OpenRouter ç»Ÿä¸€é…ç½®æ‰€æœ‰æ¨¡å‹
        if not openrouter_key:
            raise ValueError(
                "OPENROUTER_API_KEY not found. Please set it in environment variables or .env file."
            )
        
        # Jury 1: GPT-4 (Blind - ä»…åŸºäºé€»è¾‘)
        juries.append(Jury(
            name="Logic_Checker_GPT4",
            model={
                "provider": "openai_compatible",
                "base_url": "https://openrouter.ai/api/v1",
                "model_name": "openai/gpt-4",
                "api_key": openrouter_key,
                "temperature": 0.0
            },
            reference=None,  # Blind mode
            jury_prompt="è¯·ä»…æ ¹æ®é€»è¾‘ä¸€è‡´æ€§å’Œå¸¸è¯†åˆ¤æ–­æ­¤ Claim æ˜¯å¦æˆç«‹ï¼Œä¸è¦ç¼–é€ äº‹å®ã€‚"
        ))
        
        # Jury 2: Perplexity with Online Search (è‡ªå¸¦è”ç½‘æœç´¢èƒ½åŠ›)
        juries.append(Jury(
            name="Web_Detective_Perplexity",
            model={
                "provider": "openai_compatible",
                "base_url": "https://openrouter.ai/api/v1",
                "model_name": "perplexity/sonar",
                "api_key": openrouter_key,
                "temperature": 0.0
            },
            reference=None,  # ä¸éœ€è¦å¤–éƒ¨ referenceï¼Œæ¨¡å‹è‡ªå¸¦è”ç½‘æœç´¢
            jury_prompt="""You are a research engine. You MUST perform a web search for every claim to provide the most current information. Do not answer from your internal training data. Always cite your sources.

Please strictly adhere to the output guidelines. Your final decision must and can only be one of the following three phrases; creating other words is strictly prohibited:

1. "no_objection" (if online evidence supports the statement)

2. "suspicious_fact" (if the evidence is insufficient or conflicting)

3. "reasonable_doubt" (if online evidence directly refutes the statement)

You must base your judgment on the results of real-time online searches and cite specific online sources in your reasoning."""
        ))
        
        # Jury 3: Llama with RAG
        if rag_reference:
            juries.append(Jury(
                name="Archive_Keeper_Llama",
                model={
                    "provider": "openai_compatible",
                    "base_url": "https://openrouter.ai/api/v1",
                    "model_name": "meta-llama/llama-3-70b-instruct",
                    "api_key": openrouter_key,
                    "temperature": 0.2
                },
                reference=rag_reference,
                jury_prompt="è¯·åœ¨æœ¬åœ°è°£è¨€åº“ä¸­æ£€ç´¢æ˜¯å¦å­˜åœ¨åŒ¹é…çš„è®°å½•ã€‚"
            ))
        
        # Jury 4: GPT-3.5 with Basic Facts
        juries.append(Jury(
            name="Facts_Checker_GPT35",
            model={
                "provider": "openai_compatible",
                "base_url": "https://openrouter.ai/api/v1",
                "model_name": "openai/gpt-3.5-turbo",
                "api_key": openrouter_key,
                "temperature": 0.1
            },
            reference=text_reference,
            jury_prompt="""å¯¹ç…§æä¾›çš„åŸºç¡€äº‹å®çŸ¥è¯†ï¼Œåˆ¤æ–­æ­¤ Claim æ˜¯å¦ç¬¦åˆäº‹å®ã€‚
            ä½ çš„æœ€ç»ˆç»“è®ºï¼ˆdecisionï¼‰å¿…é¡»ä¸”åªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ä¸ªä¹‹ä¸€ï¼š
            1. "no_objection"
            2. "suspicious_fact"
            3. "reasonable_doubt"
            """
        ))
        
        # 5. åˆå§‹åŒ– Judge
        print("Initializing Judge...")
        judge = Judge(
            model={
                "provider": "openai_compatible",
                "base_url": "https://openrouter.ai/api/v1",
                "model_name": "openai/gpt-4",
                "api_key": openrouter_key,
                "temperature": 0.2
            },
            verdict_rules={
                "supported": {"operator": "eq", "value": 0},      # 0ä¸ªåå¯¹ -> Supported
                "suspicious": {"operator": "lt", "value": 0.5},  # < 50%åå¯¹ -> Suspicious
                "refuted": "default"  # >= 50% -> Refuted
            }
        )
        
        # 6. ç»„è£… Court
        print("Assembling Court...")
        court_instance = Court(
            prosecutor=prosecutor,
            juries=juries,
            judge=judge,
            quorum=min(3, len(juries)),  # è‡³å°‘éœ€è¦ 3 ä¸ª jury æŠ•ç¥¨
            concurrency_limit=3
        )
        
        print(f"âœ… Court initialized successfully with {len(juries)} juries!")
        return True
        
    except Exception as e:
        initialization_error = str(e)
        print(f"âŒ Court initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return False


@app.route('/')
def index():
    """æä¾›å‰ç«¯é¡µé¢"""
    return send_from_directory(app.static_folder, 'index.html')


@app.route('/api/status', methods=['GET'])
def status():
    """æ£€æŸ¥ API çŠ¶æ€"""
    return jsonify({
        "status": "ready" if court_instance else "error",
        "error": initialization_error,
        "juries_count": len(court_instance.juries) if court_instance else 0
    })


@app.route('/api/check', methods=['POST'])
def check_facts():
    """
    æ£€æŸ¥è¾“å…¥æ–‡æœ¬çš„äº‹å®å‡†ç¡®æ€§
    
    è¯·æ±‚ä½“ï¼š
    {
        "text": "è¦æ£€æŸ¥çš„æ–‡æœ¬å†…å®¹"
    }
    """
    if not court_instance:
        return jsonify({
            "error": "Court not initialized",
            "details": initialization_error
        }), 500
    
    try:
        data = request.get_json()
        text = data.get('text', '').strip()
        
        if not text:
            return jsonify({"error": "Text is required"}), 400
        
        # è¿è¡Œ Court å®¡ç†
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        report = loop.run_until_complete(
            court_instance.hear(text, domain="fact_check")
        )
        loop.close()
        
        # æå–ç»“æœ
        result = {
            "case_id": report.case_id,
            "status": report.status,
            "claims": []
        }
        
        for claim_result in report.claims:
            claim_data = {
                "text": claim_result.claim.text,
                "verdict": claim_result.verdict,
                "judge_reasoning": claim_result.judge_reasoning,
                "jury_votes": [
                    {
                        "jury_name": vote.jury_name,
                        "decision": vote.decision,
                        "confidence": vote.confidence,
                        "reason": vote.reason,
                        "reference_summary": vote.reference_summary if hasattr(vote, 'reference_summary') else None
                    }
                    for vote in claim_result.jury_votes
                ],
                "objection_ratio": claim_result.objection_ratio,
                "from_cache": claim_result.claim.source == "cache",
                "cache_id": claim_result.claim.cache_id if claim_result.claim.source == "cache" else None,
                "precedents": [
                    {
                        "id": p.precedent_id,
                        "text": p.claim,
                        "verdict": p.verdict,
                        "similarity": p.similarity_score
                    }
                    for p in (claim_result.claim.precedents or [])
                ] if hasattr(claim_result.claim, 'precedents') else []
            }
            result["claims"].append(claim_data)
        
        # ç”Ÿæˆæ€»ä½“è¯„ä¼°
        verdicts = [c.verdict for c in report.claims]
        if all(v == "supported" for v in verdicts):
            result["overall"] = "supported"
            result["summary"] = "âœ… å†…å®¹å¾—åˆ°æ”¯æŒï¼Œæœªå‘ç°è™šå‡ä¿¡æ¯ã€‚"
        elif any(v == "refuted" for v in verdicts):
            result["overall"] = "refuted"
            result["summary"] = "âŒ å†…å®¹åŒ…å«è™šå‡æˆ–ä¸å‡†ç¡®çš„ä¿¡æ¯ã€‚"
        else:
            result["overall"] = "suspicious"
            result["summary"] = "âš ï¸ éƒ¨åˆ†å†…å®¹å­˜ç–‘ï¼Œéœ€è¦è¿›ä¸€æ­¥æ ¸å®ã€‚"
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "error": "Processing failed",
            "details": str(e)
        }), 500


@app.route('/api/history', methods=['GET'])
def get_history():
    """è·å–å†å²è®°å½•"""
    if not court_instance:
        return jsonify({"error": "Court not initialized"}), 500
    
    try:
        # è¿™é‡Œå¯ä»¥å®ç°ä»æ•°æ®åº“è¯»å–å†å²è®°å½•çš„é€»è¾‘
        # ç®€åŒ–ç‰ˆæš‚æ—¶è¿”å›ç©º
        return jsonify({
            "history": [],
            "message": "History feature coming soon"
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("Model Court Web API")
    print("=" * 70)
    
    # åˆå§‹åŒ– Court
    if not initialize_court():
        print("\nâš ï¸  Court initialization failed, but server will start anyway.")
        print("Please check the error message and set up API keys properly.\n")
    
    # å¯åŠ¨ Flask æœåŠ¡å™¨
    port = int(os.getenv("PORT", 5000))
    print(f"\nğŸš€ Starting server on http://localhost:{port}")
    print(f"ğŸ“ Database location: {Path(__file__).parent}/court_history.db")
    print("\nPress Ctrl+C to stop the server.\n")
    
    app.run(host='0.0.0.0', port=port, debug=True, use_reloader=False)


if __name__ == '__main__':
    main()

