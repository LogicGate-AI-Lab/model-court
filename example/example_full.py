# model courtä½¿ç”¨ç¤ºä¾‹

import asyncio
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„ï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…åŒ…ï¼‰
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯é€‰: ä½¿ç”¨ python-dotenv è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()  # ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
except ImportError:
    print("æç¤º: å®‰è£… python-dotenv å¯è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶: pip install python-dotenv")

# -----------------------------------------------------------------------------
# 0. å¯¼å…¥ Model Court æ ¸å¿ƒåŒ…
# -----------------------------------------------------------------------------
from model_court import Court, Prosecutor, Jury, Judge
from model_court.code import SqliteCourtCode
from model_court.references import (
    LocalRAGReference
)

# -----------------------------------------------------------------------------
# 1. åŸºç¡€è®¾æ–½åˆå§‹åŒ– (Infrastructure)
# -----------------------------------------------------------------------------

# A. åˆå§‹åŒ–åˆ¤ä¾‹åº“ (æ··åˆæ£€ç´¢ï¼šSQL + Vector)
"""
è¿™é‡Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒçš„é¢„è®¾åˆ¤ä¾‹åº“ï¼Œæš‚æ—¶ä¸æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰åˆ¤ä¾‹åº“
ç°åœ¨æ”¯æŒçš„åˆ¤ä¾‹åº“æ˜¯åŒ…å«vectoræŸ¥è¯¢ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥ç›´æ¥çœ‹åˆ°çš„SQLæ•°æ®åº“
ä¹Ÿå°±æ˜¯è¯´ç”¨æˆ·å¯ä»¥ç›´æ¥çœ‹åˆ°SQLæ•°æ®åº“çš„å†…å®¹å¹¶ä¿®æ”¹ï¼ŒåŒæ—¶ç»“æœä¹Ÿä¼šåŒæ­¥æ›´æ–°å‘é‡
åœ¨Prosecutoræœç´¢çš„æ—¶å€™ï¼Œä¼šç›´æ¥è¿›è¡Œå‘é‡æŸ¥è¯¢ï¼ˆå› ä¸ºå¤§æ¦‚ç‡æ— æ³•ç›´æ¥æŸ¥åˆ°åŒæ ·çš„ç»“æœï¼‰
--------
ç›®å‰è€ƒè™‘è®¾ç½®çš„referenceç±»åˆ«åŒ…æ‹¬ï¼š
1ã€Google Search éœ€è¦APIå‚æ•°
2ã€Web Search ä½¿ç”¨å¼€æºæ–¹æ¡ˆ
3ã€RAG çŸ¥è¯†åº“ï¼Œéœ€è¦åˆå§‹åŒ–ã€å»ºåº“ï¼Œæ·»åŠ æ–°è¯æ¡éœ€è¦embeddingï¼Œå…¶ä»–ç¨‹åºä¹Ÿå¯ä»¥ä¿®æ”¹RAGä»è€Œå®ç°å¤šä»£ç†æˆ–æ­é…åä½œï¼›é»˜è®¤ä½¿ç”¨ChromaDB
4ã€SimpleTextStorage ç›´æ¥ä½¿ç”¨ä¸€ä¸ªæ–‡æœ¬æ–‡æ¡£ä½œä¸ºå¼•ç”¨æºï¼Œç”¨æˆ·å¯ä»¥æ–¹ä¾¿æ’°å†™textï¼Œtextæœ¬èº«ç›´æ¥ä¼šè¢«ä½œä¸ºä¸€ä¸ªpromptæä¾›ç»™juryï¼ˆç°åœ¨LLMçš„ä¸Šä¸‹æ–‡çª—å£éå¸¸å¤§ï¼‰
"""
court_db = SqliteCourtCode(
    db_path="./fact_check_history.db",
    default_validity_period=timedelta(days=30),
    enable_vector_search=True # å¼€å¯å‘é‡æ£€ç´¢ä»¥æŸ¥æ‰¾ç›¸ä¼¼åˆ¤ä¾‹
)

# B. åˆå§‹åŒ–å‚è€ƒèµ„æ–™ (Reference)

# èµ„æ–™æº 1: RAG çŸ¥è¯†åº“
# é€»è¾‘ä¼˜åŒ–ï¼šæ£€æµ‹åˆ°è·¯å¾„ä¸‹æœ‰ DB å°±åŠ è½½ï¼Œæ²¡æœ‰å°±æ ¹æ® source_folder åˆå§‹åŒ–
rumor_rag = LocalRAGReference(
    # ç”¨æˆ·å¯é€‰OpenAIåœ¨çº¿APIï¼Œæœ¬åœ°å°æ¨¡å‹MiniLMï¼Œæœ¬åœ°å¤§æ¨¡å‹BGE-Largeç­‰ã€‚è¿™ä¸ªä¸€å®šè¦è®¾ç½®æˆlazy loadingï¼Œç”¨çš„äººåœ¨ç”¨çš„æ—¶å€™å†ä¸‹è½½ã€‚
    # å‚æ•°åŒ…æ‹¬ï¼šMiniLM, BGE, OpenAIï¼ˆå¦‚æœé€‰OpenAIï¼Œåˆ™è¿˜è¦å¡«å†™APIå‚æ•°ï¼‰
    collection_name="common_rumors",
    persist_directory="./rag_db_storage",  # å‘é‡åº“å­˜å‚¨ä½ç½®
    source_folder="./rumor_txt_files",     # åŸå§‹æ–‡ä»¶ä½ç½®ï¼ˆç¡®ä¿æ­¤æ–‡ä»¶å¤¹å­˜åœ¨ï¼‰
    embedding_model="MiniLM",  # "MiniLM", "BGE", or "OpenAI"
    # embedding_api_key="..." # å¦‚æœé€‰OpenAIçš„embeddingæ–¹å¼ï¼Œåˆ™éœ€è¦é€‰æ‹©è¿™ä¸ª
    mode="append", # "overwrite" | "append" | "read_only"
    top_k=2
)

# -----------------------------------------------------------------------------
# 2. åˆå§‹åŒ–æ£€å¯Ÿå®˜ (Prosecutor)
# -----------------------------------------------------------------------------

prosecutor = Prosecutor(
    court_code=court_db,

    # å¯ç”¨è‡ªåŠ¨æ‹†åˆ†ï¼šå°†é•¿æ–‡æ‹†è§£ä¸ºç‹¬ç«‹ Claimï¼Œå¦‚æœä¸å¯ç”¨ï¼Œåˆ™å°†æ•´ä¸ªcaseè§†ä¸ºä¸€ä¸ªclaim
    # å¦‚æœä¸æ‹†åˆ†caseä¸ºè‹¥å¹²ä¸ªclaimï¼Œåˆ™ä¸éœ€è¦é…ç½®model
    # å¦‚æœè¦å°†caseæ‹†åˆ†ä¸ºclaimsï¼Œå¹¶å„è‡ªæ£€æŸ¥æ˜¯å¦å­˜åœ¨äºcodeä¸­ï¼Œåˆ™éœ€è¦é…ç½®model
    auto_claim_splitting=True, 
    
    # ä½¿ç”¨ OpenRouter è°ƒç”¨ GPT-3.5
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "openai/gpt-3.5-turbo",
        "temperature": 0.1
    },
    prosecutor_prompt="ä½ æ˜¯ä¸€åä¸¥æ ¼çš„æ£€å¯Ÿå®˜ã€‚è¯·å°†è¾“å…¥çš„æ¡ˆæƒ…ï¼ˆCaseï¼‰æ‹†è§£ä¸ºç‹¬ç«‹çš„ã€å¯éªŒè¯çš„äº‹å®æ–­è¨€ï¼ˆClaimsï¼‰ã€‚"
)

# -----------------------------------------------------------------------------
# 3. ç»„å»ºé™ªå®¡å›¢ (The Juries)
# -----------------------------------------------------------------------------

# é‡‡ç”¨ä¸‰æ˜æ²»ç»“æ„æ„å»ºLLMæŒ‡ä»¤ï¼šç”¨æˆ·åªéœ€è¦å†™juryé’ˆå¯¹claimç±»åˆ«çš„åˆ¤æ–­æ ‡å‡†ã€objectionçš„åˆ¤å®šé˜ˆå€¼
# å…¶ä»–çš„ç³»ç»ŸPROMPTï¼ŒåŒ…æ‹¬è¾“å‡ºæ ¼å¼ã€æµè§ˆå™¨ç±»åˆ«çš„cycleæŒ‡ä»¤ç­‰ï¼Œéƒ½åœ¨åç«¯ç”¨system promptå†™å¥½ï¼ˆç›®å‰å…ˆç¡¬ç¼–ç system promptï¼Œåç»­è€ƒè™‘åŠ å…¥ç”¨æˆ·è‡ªå®šä¹‰system promptçš„åŠŸèƒ½ï¼‰

# æé†’ç”¨æˆ·é™ªå®¡å‘˜å¯èƒ½çš„è¾“å‡ºé€‰é¡¹ï¼š"no_objection", "suspicious_fact", "reasonable_doubt"
# å¦‚æœå†™åˆ°è¾“å‡ºç»“æœç›¸å…³çš„å†…å®¹ï¼Œç”¨æˆ·ä¸€å®šè¦é’ˆå¯¹è¿™ä¸‰ä¸ªè¾“å‡ºé€‰é¡¹è¿›è¡Œé€‚åº”æ€§ä¿®æ”¹


# Jury 1: é€»è¾‘å®¡æŸ¥å‘˜ (Blind) - ä½¿ç”¨ GPT-4
jury_logic = Jury(
    name="Logic_Checker_GPT4",
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "openai/gpt-4",
        "temperature": 0.0
    },
    reference=None,  # None = Blind Modeï¼Œå¦‚æœæ²¡æœ‰å†™å‚æ•°referenceï¼Œåˆ™é»˜è®¤ä¸ºNone
    jury_prompt="è¯·ä»…æ ¹æ®é€»è¾‘ä¸€è‡´æ€§å’Œå¸¸è¯†åˆ¤æ–­æ­¤ Claim æ˜¯å¦æˆç«‹ï¼Œä¸è¦ç¼–é€ äº‹å®ã€‚"
)

# Jury 2: ç½‘ç»œä¾¦æ¢ (ä½¿ç”¨ Perplexity Sonar è”ç½‘æœç´¢æ¨¡å‹)
"""
Perplexity Sonar æ¨¡å‹è‡ªå¸¦è”ç½‘æœç´¢èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–çš„æœç´¢ API
æ¨¡å‹ä¼šè‡ªåŠ¨ä»äº’è”ç½‘è·å–æœ€æ–°ä¿¡æ¯å¹¶å¼•ç”¨æ¥æº
"""
jury_web = Jury(
    name="Web_Detective_Perplexity",
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "perplexity/sonar",
        "temperature": 0.0
    },
    reference=None,  # ä¸éœ€è¦å¤–éƒ¨ referenceï¼Œæ¨¡å‹è‡ªå¸¦è”ç½‘æœç´¢
    jury_prompt="""You are a research engine. You MUST perform a web search for every claim to provide the most current information. Do not answer from your internal training data. Always cite your sources.

è¯·ä¸¥æ ¼éµå®ˆè¾“å‡ºè§„èŒƒï¼Œä½ çš„æœ€ç»ˆç»“è®ºï¼ˆdecisionï¼‰å¿…é¡»ä¸”åªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ä¸ªçŸ­è¯­ä¹‹ä¸€ï¼Œä¸¥ç¦åˆ›é€ å…¶ä»–è¯æ±‡ï¼š
1. "no_objection" (å¦‚æœç½‘ç»œè¯æ®æ”¯æŒè¯¥è¯´æ³•)
2. "suspicious_fact" (å¦‚æœè¯æ®ä¸è¶³æˆ–æœ‰å†²çª)
3. "reasonable_doubt" (å¦‚æœç½‘ç»œè¯æ®ç›´æ¥åé©³è¯¥è¯´æ³•)

ä½ å¿…é¡»åŸºäºå®æ—¶ç½‘ç»œæœç´¢çš„ç»“æœè¿›è¡Œåˆ¤æ–­ï¼Œå¹¶åœ¨ç†ç”±ä¸­å¼•ç”¨å…·ä½“çš„ç½‘ç»œæ¥æºã€‚"""
)

# Jury 3: æ¡£æ¡ˆç®¡ç†å‘˜ (RAG) - ä½¿ç”¨ Llama 3
jury_rag = Jury(
    name="Archive_Keeper_Llama",
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "meta-llama/llama-3-70b-instruct",
        "temperature": 0.2
    },
    reference=rumor_rag,
    jury_prompt="è¯·åœ¨æœ¬åœ°è°£è¨€åº“ä¸­æ£€ç´¢æ˜¯å¦å­˜åœ¨åŒ¹é…çš„è®°å½•ã€‚"
)

# -----------------------------------------------------------------------------
# 4. ç»„å»ºæ³•åº­ (Court Assembly)
# -----------------------------------------------------------------------------

# åˆå§‹åŒ–æ³•å®˜ï¼Œè´Ÿè´£æ±‡æ€»è¿‘ä¼¼åˆ¤ä¾‹å’ŒjuriesæŠ•ç¥¨ç»“æœ - ä½¿ç”¨ GPT-4
judge = Judge(
    # æ³•å®˜æ¨¡å‹é…ç½®
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "openai/gpt-4",
        "temperature": 0.2
    }
)

# Jury 4: æ–‡æœ¬å­˜å‚¨ (Basic Facts)
basic_facts_text = """
å¸¸è§äº‹å®çŸ¥è¯†ï¼š
- åœ°çƒæ˜¯åœ†çš„ï¼ˆçƒå½¢ï¼‰
- æ°´çš„åŒ–å­¦å¼æ˜¯ H2O
- äººç±»æœ‰ 206 å—éª¨éª¼ï¼ˆæˆå¹´äººï¼‰
- å…‰é€Ÿçº¦ä¸º 299,792,458 ç±³/ç§’
- åœ°çƒç»•å¤ªé˜³å…¬è½¬
- ç–«è‹—é€šè¿‡æ¿€å‘å…ç–«ç³»ç»Ÿå·¥ä½œ
- é…’ç²¾åªèƒ½ä½“å¤–æ¶ˆæ¯’ï¼Œé¥®ç”¨æ— æ³•æ€æ­»ä½“å†…ç—…æ¯’
- åŸƒéš†Â·é©¬æ–¯å…‹æœªæ”¶è´­å¯å£å¯ä¹å…¬å¸
"""
from model_court.references import SimpleTextStorage
text_storage = SimpleTextStorage(text=basic_facts_text)

jury_facts = Jury(
    name="Facts_Checker_GPT35",
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY", "sk-or-v1-..."),
        "model_name": "openai/gpt-3.5-turbo",
        "temperature": 0.1
    },
    reference=text_storage,
    jury_prompt="""å¯¹ç…§æä¾›çš„åŸºç¡€äº‹å®çŸ¥è¯†ï¼Œåˆ¤æ–­æ­¤ Claim æ˜¯å¦ç¬¦åˆäº‹å®ã€‚
    ä½ çš„æœ€ç»ˆç»“è®ºï¼ˆdecisionï¼‰å¿…é¡»ä¸”åªèƒ½æ˜¯ä»¥ä¸‹ä¸‰ä¸ªä¹‹ä¸€ï¼š
    1. "no_objection"
    2. "suspicious_fact"
    3. "reasonable_doubt"
    """
)

# æœ€ç»ˆå®ä¾‹åŒ–çš„model courtå¯¹è±¡ï¼Œé…ç½®å¥½courtåï¼Œç”¨æˆ·åªéœ€è¦è°ƒç”¨Courtå¯¹è±¡å¹¶è¾“å…¥case contentå‚æ•°ï¼Œå°±å¯ä»¥è¿›è¡Œåº­å®¡äº†
fact_check_court = Court(
    prosecutor=prosecutor,
    juries=[jury_logic, jury_web, jury_rag, jury_facts],
    judge=judge,
    
    
    # åˆ¤å†³é€»è¾‘é…ç½® (Rule-based Verdict)
    # é€»è¾‘ï¼šç»Ÿè®¡ 'objection' (å³é no_objection) çš„ç¥¨æ•°æ¯”ä¾‹
    verdict_rules={
        # å¦‚æœ 0 ä¸ªåå¯¹ -> Supported
        "supported":  {"operator": "eq", "value": 0},   
        # å¦‚æœåå¯¹ç¥¨ < 50% (ä¸”ä¸ä¸º0) -> Suspicious
        "suspicious": {"operator": "lt", "value": 0.5}, 
        # å…¶ä»–æƒ…å†µ (>= 50%) -> Refuted (Default)
        "refuted":    "default" 
    },
    
    quorum=3,         # å¿…é¡»3ä¸ªéƒ½æˆåŠŸè¿”å›ï¼Œå¦åˆ™æµå®¡ (æˆ–è€…è®¾ä¸º2å…è®¸1ä¸ªæ‰é˜Ÿ)
    concurrency_limit=4
)
# è¿™é‡Œè¦æ³¨æ„courtåº­å®¡æ¯ä¸€ä¸ªclaimï¼Œéƒ½ä¼šå°†ç»“æœè®°å½•åˆ°codeä¸­

# -----------------------------------------------------------------------------
# 5. å¼€åº­å®¡ç† (Execution - run_trial)
# -----------------------------------------------------------------------------

async def run_trial():
    # 1. å‡†å¤‡æ¡ˆæƒ…
    case_text = """
    æœ‰äººå‘ç°äº†å—æè‡­æ°§å±‚çš„é—®é¢˜å·²ç»è¢«è§£å†³ã€‚
    """
    
    print(f"ğŸ›ï¸  Model Court å¼€åº­å—ç†ä¸­...\nCase: {case_text.strip()[:30]}...")

    # 2. æ‰§è¡Œå®¡ç† (Court.hear å†…éƒ¨è‡ªåŠ¨è°ƒåº¦ Prosecutor -> Juries -> Judge)
    # è¿”å›çš„æ˜¯ä¸€ä¸ªç»“æ„åŒ–çš„ CaseReport å¯¹è±¡
    report = await fact_check_court.hear(case_text)

    # 3. æ‰“å°å®Œæ•´åˆ¤å†³ä¹¦
    print("\n" + "="*50)
    print(f"ğŸ“œ åˆ¤å†³æ„è§ä¹¦ (Case ID: {report.case_id})")
    print("="*50)

    # éå†æ¯ä¸ª Claim çš„ç»“æœ
    for idx, claim_res in enumerate(report.claims, 1):
        print(f"\nğŸ”¹ æŒ‡æ§ {idx}: {claim_res.claim.text}")
        
        # A. å±•ç¤º Prosecutor çš„æŸ¥é‡ç»“æœ
        if claim_res.claim.source == "cache":
            print(f"   [ç›´æ¥è£å®š] å‘½ä¸­å†å²æœ‰æ•ˆåˆ¤ä¾‹ (ID: {claim_res.claim.cache_id})")
            print(f"   âš–ï¸  ç»“æœ: {claim_res.verdict.upper()}")
            continue # å¦‚æœå‘½ä¸­ç¼“å­˜ï¼Œåé¢å°±ä¸å±•ç¤ºäº†
            
        # B. å±•ç¤º Prosecutor çš„ç›¸ä¼¼åˆ¤ä¾‹è¯æ® (å¦‚æœæœ‰)
        if claim_res.claim.precedents:
            print(f"   [å†å²åˆ¤ä¾‹] å‘ç° {len(claim_res.claim.precedents)} æ¡ç›¸ä¼¼è¿‡å¾€æ¡ˆä»¶ï¼Œå·²æäº¤æ³•å®˜å‚è€ƒã€‚")

        # C. å±•ç¤º Juries æŠ•ç¥¨è¯¦æƒ…
        print("   [é™ªå®¡å›¢æŠ•ç¥¨]")
        for vote in claim_res.jury_votes:
            if vote.decision == "abstain":
                icon = "âšª"  # ç¼ºå¸­ç”¨ç©ºå¿ƒåœ†è¡¨ç¤º
            elif vote.decision == "no_objection":
                icon = "âœ…"
            else:
                icon = "âŒ"
            # å¦‚æœæ˜¯æœç´¢æ¨¡å¼ï¼Œæ‰“å°å‡ºæ‰¾åˆ°çš„ Reference
            ref_info = f" (Ref: {vote.reference_summary})" if vote.reference_summary else ""
            print(f"     {icon} {vote.jury_name}: {vote.decision}{ref_info}")
            if vote.reason:
                print(f"        Reason: {vote.reason[:60]}...")

        # D. å±•ç¤ºæœ€ç»ˆåˆ¤å†³
        print(f"   âš–ï¸  æœ€ç»ˆåˆ¤å†³: ã€{claim_res.verdict.upper()}ã€‘")
        print(f"   ğŸ“ æ³•å®˜ç»¼è¿°: {claim_res.judge_reasoning}")

    # 4. å¼‚å¸¸å¤„ç†å±•ç¤º
    if report.status == "mistrial":
        print(f"\nâš ï¸ å®¡åˆ¤æ— æ•ˆ (Mistrial): {report.error_message}")

# è¿è¡Œ
if __name__ == "__main__":
    asyncio.run(run_trial())

