model court

核心思想：多次采样ensembling + 三角结构（主模型、证据模型、验证模型）

模型法庭在未来将用在以下内容上：
safety check 是否违规
hallucination check 是否胡编乱造
answer selection 多个答案选最优
在我的财税AI上也能利用，用来审查结果是否正确

======================================================================
一、model court 准备、初始化等
======================================================================

model court的统一接口

model court要做成pypi package，所以要对所有接口进行高度封装化、可定制化

例如，只要import modelcourt，然后设置：
{
  court = ...
  juries = ...
  judge = ...
  court_code = ...
}
就可以，具体的设置规则需要根据我们最终选定的功能模块来设置

这里最大的麻烦在于court_code和reference的设置问题，如何才能设置为可插拔解耦？

=========================================================================

reference：参考资料
可以设置不同的、相互独立的参考资料，比如：用户自定义文件、互联网实时查询等
这里考虑rag、agent search、file search等不同方案，并考虑哪个方案最方便、最适合整合到package中
初步考虑设置互联网搜索结果、用户可以方便记录的text、用户需要设置以及embedding的rag、agent search等（取决于难易程度）

===========================================================================

court_code: 判例（判例是针对claim的）
这个是一个特殊的参考资料，是给法官使用的
判例需要增加一个有效期设定，在一些特定领域比如金融行业可能会有valid_range的情况，所以要有：
{
  valid_from: datetime | None 
  valid_until: datetime | None
}




======================================================================
二、model court 执行过程（按照处理顺序）
======================================================================

INPUT: case

case就是INPUT进来判断是否为真的内容（比如fact check中要check是否包含非事实对象的fact）
这里预先考虑fact check、金融领域check、法律领域check三种default设定


======================================================================

Prosecutor: 检察官
INPUT: case
OUTPUT:
{
  reject: 是否受理case
  check cache：查重的结果，可能有若干个
  claims：case会被分成数个claims
}


检察官先查询court_code，判断同类case是否已经被判定过；
如果判定过，则直接给出判定过的结果，不需要再次判定
如果没有判定过，才进入庭审

check cache查重
？？？这里有个问题是code如果被检察官用过，那么judge最后就没有用的必要了？因为如果已经有code，那么就不会进入到庭审阶段
这里可以分为三类：
  - 查到了完全相同的claim，且在有效期内，那么就reject case，返回code中的判例结果
  - 查到了近似的claim、相同但过期的claim，那么就整理好，后续要交给judge审判
  - 没有查到近似的claim，那么就记录没有相似判例

另外prosecutor还有个事情就是要进行预处理工作
把输入的case整理为若干个独立的claim
每一条claim都会被单独check，最终庭审的内容也是针对每一条claim的（类似于某一项罪）


===========================================================================

juries 

INPUT: claim for each jury 
OUTPUT: verdict 


juries: multiple sampling
裸llm，3-9个，默认3个，需要用户设置（这里需要探明不同llm的api的差异点）
这里推荐用户设置相互独立、查阅不同reference的juries，来提升独立性，避免犯共同错误

每一个jury都是一个独立的LLM管道，其查阅的资料也是相互独立的，互相之间不同步信息、不使用同样的检查方式，从而保证审理独立性

对同一输入，让多个模型生成多个解答，然后通过投票来决定jury结果。
用户需要设置model的数量和model调用的llm api
{
  juries_amount: 3 - 9 ※ 最少3个，最多9个，可以是偶数个
  {
    jury_num: 1
    jury_name: chatgpt 
    model_settings: {
      ...
    }
  }
}

每一个jury都可以设置blind：
{
  blind: true | false
  code_reference: web | text | rag | agent_search | file_search
}

每一个model都可以raise objection：
{
  "objection": " no_objection | suspecious_fact | reasonable_doubt ",
  "confidence": 0.0-1.0,
  "reason": "为什么觉得有问题 / 或者为什么觉得没问题"
}

为了保证独立性，设置的时候尽量保证使用不同的llm、不同的语料库、不同的资料库、不同的prompt设定、不同的温度等
并且保证有保守型jury、创新思考型jury，即通过prompt来设定性格迥异的juries，减少结论的同质化倾向
jury之间相互独立，每个jury只能接收case信息，并输出自己的结果

jury掉队的问题：如果一个jury挂掉了，其结果怎么算？这个也要考虑，如果是挂掉（比如设置成弃权），那么弃权怎么算？多少个弃权会导致court变成hang状态？
如果个别jury掉队后导致active juries总数不到3个（这个法定人数quorum可以设定），那么就流审（mistrial），case被记录为hang jury（悬案）
个别model如果没有类似互联网查询直到确定结果的，也可以给出弃权（abstain），弃权的话视作掉队

=========================================================================

judge 

INPUT:
{
  prosecutor的code查重结果
  juries们各自的独立verdict
}


judge会根据juries的结果和prosecutor提交的近似案例给出本case的结果：
{
  verdict_id: string 
  domain: fact_check | finance | law | other 
  decision: supported | suspecious | refuted
}
这个应当可以让用户自己定义结果，比如fact check的话结果肯定是true fact, fake fact, suspecious这三种
所以judge应当给出一个具体的、显而易见的总结，分别代表：没问题（无object）、有疑问（少于半数object）、重大问题（多于半数object）
这三个分别是：没问题（supported）、有疑问（suspecious）、重大问题（refuted）
这里的decision用户可以自定义，也可以使用默认的设置（默认的就是全部通过、少于半数、等于或多于半数三种）

庭审结果会被记录为一个“判决意见书”，并且会被记录为court_code保存。
用户可以直接打开court_code修改记录，来人为修改裁定结果，从而让下一次judge更符合要求

{
  case_id: ...
  case_title: ...
  case_description: ...
  verdict: ...
  verdict_description: ...
}

例：
{
  case_id: 00001
  case_title: 
  case_description: 判断中国是否属于
  verdict "suspicious",
  verdict_description: "3 juries中有 1 名提出异议，其中 1 名基于历史 fact_feedback 指出该事实曾被标记为可疑。"
}



======================================================================
三、示例使用
======================================================================

Fact Check中的计划：

court model = 3 different LLMs：
  ChatGPT 裸审查，PROMPT侧重于事实等
  Gemini 互联网搜索功能，使用google_search_grounding，需要单独开启
  RAG (预设的一些常见谣言，录入到RAG中) + llama/QWen，用开原模型搭配RAG更合适

========================================================================

参考配置伪代码