# Model Court: A Multi-Model Ensemble Framework for Verification

[![EN](https://img.shields.io/badge/lang-EN-blue)](README.md) [![ZH](https://img.shields.io/badge/lang-ZH-red)](README_zh.md)

## Project Overview (V0.0.2)

Model Court is an open-source framework designed to make cross-verification and fact-checking with multiple models easier. **Model Court is inspired by concepts from the U.S. courtroom system, using the roles of Prosecutor, Jury, and Judge to verify facts, with support for internet search, RAG-based retrieval, and more.**  
The current version is **0.0.2**, released on **2025-11-30**, and provides the basic core functionality.

Model Court performs AI content verification using a courtroom-style process:

- **Prosecutor**: Preprocesses the case, queries historical precedents. If a valid precedent already exists and has not expired, the result is returned directly without entering a full trial.
- **Jury**: Multiple independent LLM evaluators. Each juror is independent; it is recommended that each uses different retrieval tools and models from different providers.
- **Judge**: Aggregates votes and produces the final verdict, which is then stored as a precedent in the precedent database.

This courtroom-style process can **improve reliability in scenarios where LLM outputs need to be verified**, such as:

- **Fact-checking**: Determining the factual accuracy of news and social media content.
- **Content moderation**: Detecting harmful, violating, or misleading content.
- **Knowledge Q&A**: Verifying the correctness of AI-generated answers.
- **Academic research**: Improving robustness via multi-model ensemble.
- **Compliance checking**: Verifying whether content complies with certain rules or standards.

**The basic courtroom flow is as follows:**

```
Case Input â†’ Prosecutor â†’ [Juror1, Juror2, ..., JurorN] â†’ Judge â†’ Verdict
                â†“                         â†“
         Precedent Database          Reference Sources
           (Past Rulings)              (Evidence)
```

For the full courtroom process, see the detailed introduction below.

---

Related documents:

- [API Documentation](api_docs.md) â€“ Full API reference and examples  
- [Installation Guide](INSTALLATION.md) â€“ Detailed installation and configuration  
- [Changelog](CHANGELOG.md) â€“ Version history  
- [Contribution Guide](CONTRIBUTING.md) â€“ How to contribute to this project  

## Installation

This project is published on [PyPI](https://pypi.org/project/model-court/) and can be installed via `pip`.

**Install**

```bash
# Install core package (minimal dependencies)
pip install model-court

# Or install the full version (includes all LLM, RAG, search features)
pip install model-court[full]

# Development install (from source)
pip install -e .
pip install -e .[full]  # Full version from source
```

> **Note:** The package name is `model-court` (with a hyphen), but the import name is `model_court` (with an underscore).

---

## Detailed Introduction

### Full Courtroom Workflow

**The full courtroom workflow is as follows:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ðŸ›ï¸ Model Court             â”‚
â”‚              Main Courtroom Flow         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Input Case Text      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚        1. Prosecutor (Prosecutor)     â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Optionally split the case into      â”‚
   â”‚   multiple claims (if enabled)        â”‚
   â”‚ â€¢ Query precedent DB (SQL + Vector)   â”‚
   â”‚   to avoid redundant evaluation       â”‚
   â”‚     - Cache hit â†’ return past ruling  â”‚
   â”‚     - Similar precedent â†’ provide     â”‚
   â”‚       as reference to the Judge       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     2. Launch Multiple Juries in Parallel   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚           ðŸ§‘â€âš–ï¸  Jury Voting Process           â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Cross-validate claims using independent LLMs â”‚
   â”‚ to reduce hallucinations.                    â”‚
   â”‚ Each jury can focus on different criteria,   â”‚
   â”‚ either purely model-based or using pluggable â”‚
   â”‚ reference sources:                           â”‚
   â”‚                                              â”‚
   â”‚ â‘  Logical review: evaluate based on logic    â”‚
   â”‚    and common sense only.                    â”‚
   â”‚ â‘¡ Web search: validate claims using real-    â”‚
   â”‚    time web search (supports iterative       â”‚
   â”‚    verification).                            â”‚
   â”‚ â‘¢ RAG: use integrated RAG pipeline; Model    â”‚
   â”‚    Court handles creation, embedding, and    â”‚
   â”‚    retrieval.                                â”‚
   â”‚ â‘£ Text document store: a basic fact store    â”‚
   â”‚    providing textual factual references.     â”‚
   â”‚                                              â”‚
   â”‚ All jury members choose exactly one of:      â”‚
   â”‚      â€¢ "no_objection"     (support)          â”‚
   â”‚      â€¢ "suspicious_fact"  (insufficient      â”‚
   â”‚                            evidence)         â”‚
   â”‚      â€¢ "reasonable_doubt" (counter-evidence) â”‚
   â”‚ Note: if a jury member fails or cannot       â”‚
   â”‚ provide a conclusion, it is counted as       â”‚
   â”‚ "abstains".                                  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚             3. Judge (Judge)          â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       â”‚ â€¢ Aggregates jury votes               â”‚
       â”‚ â€¢ References similar precedents       â”‚
       â”‚ â€¢ Rule-based verdict logic; requires  â”‚
       â”‚   reaching a minimum quorum of valid  â”‚
       â”‚   votes                               â”‚
       â”‚       â–¶ supported  (no objections)    â”‚
       â”‚       â–¶ suspicious (some objections)  â”‚
       â”‚       â–¶ refuted   (majority oppose)   â”‚
       â”‚ â€¢ Outputs Judge reasoning             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚      4. Court Generates CaseReport    â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ â€¢ Structured list of claims           â”‚
     â”‚ â€¢ Jury votes and rationales           â”‚
     â”‚ â€¢ Referenced precedents (if any)      â”‚
     â”‚ â€¢ Final judgment                      â”‚
     â”‚ â€¢ Persisted into precedent DB         â”‚
     â”‚   (SQL + Vector)                      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### Full Example

You must configure the Prosecutor, Jury, and Judge before you can use Model Court. The setup is simple: specify which models to use and configure their APIs.  
We recommend using **OpenRouter**, which allows you to access many LLMs with a single API key. The system also supports ChatGPT, Gemini, Claude, etc. See later sections for more details.

> **Note: the courtroom process must be run asynchronously.**

```python
import asyncio
import os
from pathlib import Path
from dotenv import load_dotenv  # Load .env for environment variables

from model_court import Court, Prosecutor, Jury, Judge
from model_court.code import SqliteCourtCode
from model_court.references import SimpleTextStorage, LocalRAGReference

# Load environment variables
load_dotenv()

# ----------------------------------------------------------------------
# 0. Preparation
# ----------------------------------------------------------------------
# Before running this demo, please make sure you have completed:
#
# 1. Environment configuration (.env)
#    - Create a .env file in the current directory
#    - Add API key, e.g.:
#      OPENROUTER_API_KEY=sk-or-v1-xxxx...
#
# 2. Virtual environment (recommended)
#    - python -m venv .venv
#    - source .venv/bin/activate  (Windows: .venv\Scripts\activate)
#
# 3. Install dependencies
#    - pip install model-court python-dotenv
#    - pip install model-court[full]  # Recommended if using RAG
#
# 4. Prepare data files (paths used in the code; below we use RAG jury
#    and text-based jury as examples)
#    Make sure the directory structure looks like:
#
#    .
#    â”œâ”€â”€ .env
#    â”œâ”€â”€ example_court.py (this file)
#    â””â”€â”€ data/
#        â”œâ”€â”€ rag_init_files/           <-- initialization corpus for RAG jury
#        â”‚   â””â”€â”€ rumors_2024.txt       (any text files as knowledge base)
#        â””â”€â”€ text_documents/           <-- reference files for text-based jury
#            â””â”€â”€ basic_facts.txt       (basic factual text such as policies,
#                                      legal clauses, etc.)
# ----------------------------------------------------------------------


# ----------------------------------------------------------------------
# 1. Initialize Court: configure Prosecutor, Juries, and Judge
# ----------------------------------------------------------------------
def build_court() -> Court:
    # 1. Initialize precedent store (persistent storage)
    court_code = SqliteCourtCode(
        db_path="./fact_check_history.db",
        enable_vector_search=True
    )

    # 2. Initialize Prosecutor (check precedents and split claims)
    prosecutor = Prosecutor(
        court_code=court_code,
        auto_claim_splitting=False,  # Set True to split case into multiple claims
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "openai/gpt-3.5-turbo",
            "temperature": 0.1
        },
        prosecutor_prompt=(
            "You are a strict prosecutor. Break the input case into "
            "independent, verifiable factual claims."
        )
    )

    # 3. Initialize juries (ensure diversity to keep them independent)

    # [Logical perspective]
    jury_logic = Jury(
        name="Logic_Jury",
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "openai/gpt-4",
            "temperature": 0.0
        },
        reference=None,
        jury_prompt=(
            "Evaluate whether the statement is reasonable based on logic "
            "and common sense only. Do not fabricate information."
        )
    )

    # [Web search perspective]
    jury_web = Jury(
        name="Web_Jury",
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "perplexity/sonar",  # This model has built-in web access
            "temperature": 0.0
        },
        reference=None,
        jury_prompt=(
            "Use web search to verify each claim and base your judgment "
            "on the latest information."
        )
    )

    # [Local RAG perspective]
    jury_rag = Jury(
        name="RAG_Jury",
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "meta-llama/llama-3-70b-instruct",
            "temperature": 0.2
        },
        reference=LocalRAGReference(
            collection_name="common_rumors",
            persist_directory="./rag_db_storage",
            source_folder="./data/rag_init_files",
            embedding_model="MiniLM",
            mode="append",
            top_k=2
        ),
        jury_prompt="Query the local rumor knowledge base to see if related records exist."
    )

    # [Text document perspective]
    basic_facts_path = Path("./data/text_documents/basic_facts.txt")

    # Basic file check for demo convenience
    if not basic_facts_path.exists():
        raise FileNotFoundError(
            f"Demo failed: please create file {basic_facts_path} first."
        )

    jury_facts = Jury(
        name="Facts_Jury",
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "openai/gpt-3.5-turbo",
            "temperature": 0.1
        },
        reference=SimpleTextStorage(text=basic_facts_path.read_text(encoding="utf-8")),
        jury_prompt="Compare each claim against the basic facts text to decide if it is true."
    )

    # 4. Initialize Judge
    judge = Judge(
        model={
            "provider": "openai_compatible",
            "base_url": "https://openrouter.ai/api/v1",
            "api_key": os.getenv("OPENROUTER_API_KEY"),
            "model_name": "openai/gpt-4",
            "temperature": 0.2
        }
    )

    # 5. Assemble the Court
    return Court(
        prosecutor=prosecutor,
        juries=[jury_logic, jury_web, jury_rag, jury_facts],
        judge=judge,
        verdict_rules={
            "supported": {"operator": "eq", "value": 0},
            "suspicious": {"operator": "lt", "value": 0.5},
            "refuted": "default"
        },
        quorum=3,
        concurrency_limit=4
    )


# ----------------------------------------------------------------------
# 2. Run a demo
# ----------------------------------------------------------------------
async def demo():
    # Instantiate the court; RAG models will be loaded on first run
    court = build_court()

    # Case input
    case_text = "China and the United States have already had diplomatic relations for 300 years, and the two governments held a celebration for this."

    # Hear the case asynchronously
    report = await court.hear(case_text)

    # Display contents of the Report object
    print(f"
{'='*20} Case Report (ID: {report.case_id}) {'='*20}")

    for i, res in enumerate(report.claims, 1):
        print(f"
[Claim {i}] {res.claim.text}")

        # Print detailed jury votes
        for vote in res.jury_votes:
            print(f"  - {vote.jury_name}: {vote.decision}")
            if vote.reason:
                print(f"    Reason: {vote.reason[:60]}...")

        print(f"
  => Judge Verdict: [{res.verdict}]")
        print(f"  => Judge Reasoning: {res.judge_reasoning}")

    print(f"
{'='*60}")


if __name__ == "__main__":
    # The court process must be run asynchronously
    asyncio.run(demo())
```

More examples can be found under the `example` folder in the project:

- [Full CLI example](example/example_full.py) â€“ Command-line script demonstrating all major features (similar to the example above).  
- [Web app example](example/backend/app.py) â€“ A fact-checking web application that shows how to integrate Model Court into a web UI.

## Project Configuration

### LLM

The project supports the following LLM providers:

| Provider              | Description                          | Example Models                      |
| --------------------- | ------------------------------------ | ----------------------------------- |
| `openai`              | Native OpenAI API                    | gpt-4, gpt-3.5-turbo                |
| `google`              | Google Gemini                        | gemini-pro, gemini-1.5-pro          |
| `anthropic`           | Anthropic Claude                     | claude-3-5-sonnet, claude-3-opus    |
| `openai_compatible`   | OpenAI-compatible API (**recommended**) | Access all models via OpenRouter |
| `custom`              | Custom provider                      | Local models or self-hosted service |

**Recommended: `openai_compatible` + OpenRouter**

OpenRouter provides a unified interface to many LLMs. With a single API key, you can access over 100 models, including some that are free (e.g., deepseek).

```python
# Environment variable
export OPENROUTER_API_KEY="sk-or-v1-..."

# In code
model_config = {
    "provider": "openai_compatible",
    "base_url": "https://openrouter.ai/api/v1",
    "api_key": os.getenv("OPENROUTER_API_KEY"),
    "model_name": "openai/gpt-4",  # Or any other supported model
}
```

Supported models list: https://openrouter.ai/models

### Reference

The project supports the following built-in reference sources and modes:

| Reference Type          | Description        | Typical Use Case                     |
| ----------------------- | ------------------ | ------------------------------------ |
| `SimpleTextStorage`     | Plain text docs    | Simple fact lists, rule descriptions |
| `LocalRAGReference`     | Local RAG KB       | Semantic search over large corpora   |
| `GoogleSearchReference` | Google Custom Search | Need real-time web verification   |
| `None`                  | Blind mode         | Pure logical reasoning without external sources |

**1. Simple text storage**

```python
from model_court.references import SimpleTextStorage
from pathlib import Path

# Read from file
facts_file = Path("./data/rag_documents/basic_facts.txt")
with open(facts_file, "r", encoding="utf-8") as f:
    facts_text = f.read()

reference = SimpleTextStorage(text=facts_text)

# Or directly pass a small text block (for quick tests)
# reference = SimpleTextStorage(text="Fact 1: The Earth is round
Fact 2: The chemical formula of water is H2O")
```

**2. Local RAG knowledge base**

```python
from model_court.references import LocalRAGReference

reference = LocalRAGReference(
    collection_name="my_knowledge",
    persist_directory="./vector_db",
    source_folder="./documents",  # Folder with txt/md files
    embedding_model="MiniLM",     # "MiniLM", "BGE", or "OpenAI"
    mode="append",                # "overwrite", "append", or "read_only"
    top_k=3                       # Return top 3 most relevant chunks
)
```

**3. Google Search**

```python
from model_court.references import GoogleSearchReference

reference = GoogleSearchReference(
    api_key="your-google-api-key",
    search_engine_id="your-search-engine-id",
    num_results=5
)
```

**4. Blind mode (no reference)**

```python
jury = Jury(
    name="Logic_Checker",
    model=model_config,
    reference=None,  # No external references
    jury_prompt="Judge only based on logic and common sense."
)
```

## Project Structure

```text
model_court/
â”œâ”€â”€ model_court/             # Core package
â”‚   â”œâ”€â”€ core/                # Core components
â”‚   â”‚   â”œâ”€â”€ models.py        # Data models
â”‚   â”‚   â”œâ”€â”€ court.py         # Court main class
â”‚   â”‚   â”œâ”€â”€ prosecutor.py    # Prosecutor class
â”‚   â”‚   â”œâ”€â”€ jury.py          # Jury class
â”‚   â”‚   â””â”€â”€ judge.py         # Judge class
â”‚   â”œâ”€â”€ llm/                 # LLM provider layer
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â”œâ”€â”€ google_provider.py
â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”‚   â”œâ”€â”€ custom_provider.py
â”‚   â”‚   â””â”€â”€ factory.py       # Provider factory
â”‚   â”œâ”€â”€ references/          # Reference sources
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ google_search.py
â”‚   â”‚   â”œâ”€â”€ web_search.py
â”‚   â”‚   â”œâ”€â”€ rag_reference.py
â”‚   â”‚   â””â”€â”€ text_storage.py
â”‚   â”œâ”€â”€ embeddings/          # Embedding models
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base classes
â”‚   â”‚   â”œâ”€â”€ minilm.py
â”‚   â”‚   â”œâ”€â”€ bge.py
â”‚   â”‚   â””â”€â”€ openai_embedding.py
â”‚   â”œâ”€â”€ code/                # Court Code (precedent store)
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base classes
â”‚   â”‚   â””â”€â”€ sqlite_code.py
â”‚   â””â”€â”€ utils/               # Helper utilities
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ example/                 # Usage examples
â”‚   â”œâ”€â”€ example_full.py      # Full CLI example
â”‚   â”œâ”€â”€ backend/             # Web API server
â”‚   â”œâ”€â”€ frontend/            # Web frontend
â”‚   â””â”€â”€ data/                # Example data
â”œâ”€â”€ api_docs.md              # API documentation
â”œâ”€â”€ README.md                # Project description
â”œâ”€â”€ CHANGELOG.md             # Changelog
â”œâ”€â”€ CONTRIBUTING.md          # Contribution guide
â”œâ”€â”€ LICENSE                  # License
â”œâ”€â”€ pyproject.toml           # Project configuration
â”œâ”€â”€ setup.py                 # Setup script
â””â”€â”€ requirements.txt         # Dependencies
```

.

## Advanced Features

### Custom Verdict Rules

You can customize verdict rules according to your business requirements:

```python
# Example 1: Strict mode (single veto)
court_strict = Court(
    prosecutor=prosecutor,
    juries=[jury_logic, jury_web, jury_rag, jury_facts],
    judge=judge,
    verdict_rules={
        "supported": {"operator": "eq", "value": 0},   # Must have 0 opposing votes
        "refuted": "default"  # Any opposing vote â†’ refuted
    }
)

# Example 2: Lenient mode (majority rule)
court_lenient = Court(
    prosecutor=prosecutor,
    juries=[jury_logic, jury_web, jury_rag, jury_facts],
    judge=judge,
    verdict_rules={
        "supported": {"operator": "lt", "value": 0.25},   # Opposition < 25%
        "suspicious": {"operator": "lt", "value": 0.75},  # Opposition < 75%
        "refuted": "default"  # Opposition >= 75%
    }
)

# Example 3: Multi-level rating
court_detailed = Court(
    prosecutor=prosecutor,
    juries=[jury_logic, jury_web, jury_rag, jury_facts],
    judge=judge,
    verdict_rules={
        "clearly_true": {"operator": "eq", "value": 0},     # 0 opposition
        "likely_true": {"operator": "lt", "value": 0.3},    # < 30% opposition
        "uncertain": {"operator": "lt", "value": 0.6},      # < 60% opposition
        "likely_false": {"operator": "lt", "value": 0.9},   # < 90% opposition
        "clearly_false": "default"  # >= 90% opposition
    }
)
```

### Automatic Claim Splitting

For complex statements, you can automatically split them into multiple independent claims:

```python
prosecutor = Prosecutor(
    court_code=court_code,
    auto_claim_splitting=True,  # Enable auto splitting
    model={
        "provider": "openai_compatible",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key": os.getenv("OPENROUTER_API_KEY"),
        "model_name": "openai/gpt-3.5-turbo",
    },
    prosecutor_prompt="Split the case into independent, verifiable factual claims."
)

# Input: "The Earth is flat, and the Sun orbits the Earth."
# Automatically split into:
# Claim 1: "The Earth is flat."
# Claim 2: "The Sun orbits the Earth."
```

### Precedent Caching System

Automatically cache past rulings to avoid repeated evaluation:

```python
from datetime import timedelta

court_code = SqliteCourtCode(
    db_path="./court_history.db",
    enable_vector_search=True,              # Vector search for similar cases
    default_validity_period=timedelta(days=30)  # Precedent validity period
)

# First check: full pipeline, typically 10â€“30 seconds
report1 = await court.hear("The Earth is flat.")

# Second check with same content: directly return cached result, < 1 second
report2 = await court.hear("The Earth is flat.")
```

## FAQ

### Q: Why are the package name and import name different?

This is intentional:

- **Installation**: `pip install model-court` (PyPI package name, with hyphen)  
- **Import**: `from model_court import ...` (Python module name, with underscore)

This is a common pattern in Python because module names cannot contain hyphens.

### Q: I get `ModuleNotFoundError: No module named 'model_court'`

Please ensure the package is installed correctly:

```bash
# From project root (where pyproject.toml is located)
pip install -e .

# Or install from PyPI
pip install model-court
```

### Q: How do I use different LLMs?

Recommended: use OpenRouter as a unified entrypoint:

```python
model_config = {
    "provider": "openai_compatible",
    "base_url": "https://openrouter.ai/api/v1",
    "api_key": os.getenv("OPENROUTER_API_KEY"),
    "model_name": "MODEL_NAME",  # e.g., openai/gpt-4, anthropic/claude-3-5-sonnet
}
```

Supported model list: https://openrouter.ai/models

You can of course also use the official APIs for ChatGPT, Gemini, Claude, or school/corporate APIs that are OpenAI-compatible.

### Q: How can I reduce API costs?

Suggestions:

1. Use cheaper or free APIs when possible.  
2. Use smaller or local models (local inference is supported).  
3. Use the precedent caching system to avoid repeated evaluation.  
4. Reduce the number of juries.  
5. Use cheaper models such as `gpt-3.5-turbo`.  
6. Disable automatic claim splitting (`auto_claim_splitting=False`).

### Q: What if evaluation is slow?

Normally, evaluating multiple models in parallel takes about **10â€“30 seconds**. To speed up:

- Enable and leverage precedent caching (second run on the same content is < 1 second).  
- Reduce the number of juries.  
- Choose faster models.  
- Tune the `concurrency_limit` parameter.

## License & Citation

This project is licensed under the MIT License and can be used freely, including for commercial purposes.

If you use Model Court in your research, please cite:

```bibtex
@software{model-court,
  title={Model Court: A Multi-Model Ensemble Framework for Verification},
  author={Jeff Liu},
  year={2025},
  url={https://github.com/LogicGate-AI-Lab/model-court}
}
```
